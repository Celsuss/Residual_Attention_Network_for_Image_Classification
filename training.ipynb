{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36764bit1e39c9a795c4477489becf06625292af",
   "display_name": "Python 3.6.7 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Tensorflow version: 2.1.0\n"
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "import dataProcessing\n",
    "from models.model import AttentionResNet\n",
    "from models.refModel import RefConvNet\n",
    "\n",
    "print('Tensorflow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment this, only for debuging\n",
    "# @tf.function\n",
    "def trainStep(model, x, y, loss_op, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_op(y, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, predictions)\n",
    "    \n",
    "# TODO: Uncomment this, only for debuging\n",
    "# @tf.function\n",
    "def testStep(model, x, y, loss_op, test_loss, test_accuracy):\n",
    "    predictions = model(x)\n",
    "    loss = loss_op(y, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Data shape: (32, 32, 3)\n"
    }
   ],
   "source": [
    "def getData():\n",
    "    x_train, y_train, x_test, y_test = utils.getCifar10Dataset()\n",
    "    train_data, x_test, y_test = dataProcessing.preprocessData(x_train, y_train, x_test, y_test, batch_size=128)\n",
    "    return train_data, x_test, y_test\n",
    "\n",
    "train_data, x_test, y_test = getData()\n",
    "\n",
    "print('Data shape: {}'.format(x_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, x_test, y_test, loss_op, optimization, epochs):\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "    n_batches = len(train_data)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        n_batch = 0\n",
    "        for x, y in train_data:\n",
    "            n_batch+=1\n",
    "            template = '[Batch {}/{}] Loss: {:.3f}, Accuracy: {:.2%}'\n",
    "            print(template.format(n_batch, n_batches, train_loss.result(), train_accuracy.result()), end='\\r')\n",
    "            trainStep(model, x, y, loss_op, optimization, train_loss, train_accuracy)\n",
    "            \n",
    "            if n_batch >= n_batches:\n",
    "                # we need to break the loop by hand because\n",
    "                # the generator loops indefinitely\n",
    "                break\n",
    "\n",
    "        testStep(model, x_test, y_test, loss_op, test_loss, test_accuracy)\n",
    "\n",
    "        template = '\\n[Epoch {}/{}] Loss: {:.3f}, Accuracy: {:.2%}, Test Loss: {:.3f}, Test Accuracy: {:.2%}'\n",
    "        print(template.format(epoch+1, epochs, train_loss.result(), train_accuracy.result(),\n",
    "                test_loss.result(), test_accuracy.result()))\n",
    "\n",
    "        # Reset the metrics for the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 5\n",
    "\n",
    "loss_op = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_25 (Conv2D)           (None, 30, 30, 32)        896       \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 13, 13, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\nconv2d_27 (Conv2D)           (None, 4, 4, 64)          36928     \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 64)                65600     \n_________________________________________________________________\ndense_7 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 122,570\nTrainable params: 122,570\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# First train a normal 2D conv network\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[Batch 256/391] Loss: 6.239, Accuracy: 10.92%"
    }
   ],
   "source": [
    "train(model, train_data, x_test, y_test, loss_op, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}