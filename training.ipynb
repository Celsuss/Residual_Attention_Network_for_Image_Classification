{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36764bit1e39c9a795c4477489becf06625292af",
   "display_name": "Python 3.6.7 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Tensorflow version: 2.1.0\n"
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "import dataProcessing\n",
    "from models.model import AttentionResNet\n",
    "from models.refModel import RefConvNet\n",
    "\n",
    "print('Tensorflow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment this, only for debuging\n",
    "# @tf.function\n",
    "def trainStep(model, x, y, loss_op, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_op(y, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, predictions)\n",
    "    \n",
    "# TODO: Uncomment this, only for debuging\n",
    "# @tf.function\n",
    "def testStep(model, x, y, loss_op, test_loss, test_accuracy):\n",
    "    predictions = model(x)\n",
    "    loss = loss_op(y, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Data shape: (32, 32, 3)\n"
    }
   ],
   "source": [
    "def getData():\n",
    "    x_train, y_train, x_test, y_test = utils.getCifar10Dataset()\n",
    "\n",
    "    x_train = normalize(x_train)\n",
    "    x_test = normalize(x_test)\n",
    "    y_train = keras.utils.to_categorical(y_train)\n",
    "    y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "    return train_data, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = utils.getCifar10Dataset()\n",
    "\n",
    "x_train = dataProcessing.normalize(x_train)\n",
    "x_test = dataProcessing.normalize(x_test)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "print('Data shape: {}'.format(x_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, x_test, y_test, loss_op, optimization, epochs):\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "    n_batches = len(train_data)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        n_batch = 0\n",
    "        for x, y in train_data:\n",
    "            n_batch+=1\n",
    "            template = '[Batch {}/{}] Loss: {:.3f}, Accuracy: {:.2%}'\n",
    "            print(template.format(n_batch, n_batches, train_loss.result(), train_accuracy.result()), end='\\r')\n",
    "            trainStep(model, x, y, loss_op, optimization, train_loss, train_accuracy)\n",
    "            \n",
    "            if n_batch >= n_batches:\n",
    "                # we need to break the loop by hand because\n",
    "                # the generator loops indefinitely\n",
    "                break\n",
    "\n",
    "        testStep(model, x_test, y_test, loss_op, test_loss, test_accuracy)\n",
    "\n",
    "        template = '\\n[Epoch {}/{}] Loss: {:.3f}, Accuracy: {:.2%}, Test Loss: {:.3f}, Test Accuracy: {:.2%}'\n",
    "        print(template.format(epoch+1, epochs, train_loss.result(), train_accuracy.result(),\n",
    "                test_loss.result(), test_accuracy.result()))\n",
    "\n",
    "        # Reset the metrics for the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_epochs = 5\n",
    "n_batch_size = 32\n",
    "\n",
    "loss_op = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_28 (Conv2D)           (None, 30, 30, 32)        896       \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_29 (Conv2D)           (None, 13, 13, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_10 (MaxPooling (None, 6, 6, 64)          0         \n_________________________________________________________________\nconv2d_30 (Conv2D)           (None, 4, 4, 64)          36928     \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 64)                65600     \n_________________________________________________________________\ndense_9 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 122,570\nTrainable params: 122,570\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# First train a normal 2D conv network\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[Batch 390/391] Loss: 6.219, Accuracy: 12.58%[Batch 391/391] Loss: 6.217, Accuracy: 12.59%\n[Epoch 1/5] Loss: 6.216, Accuracy: 12.61%, Test Loss: 6.177, Test Accuracy: 17.89%\n[Batch 391/391] Loss: 6.187, Accuracy: 14.93%\n[Epoch 2/5] Loss: 6.187, Accuracy: 14.93%, Test Loss: 6.187, Test Accuracy: 13.81%\n[Batch 390/391] Loss: 6.169, Accuracy: 14.42%[Batch 391/391] Loss: 6.169, Accuracy: 14.42%\n[Epoch 3/5] Loss: 6.172, Accuracy: 14.41%, Test Loss: 6.145, Test Accuracy: 16.97%\n[Batch 390/391] Loss: 6.102, Accuracy: 18.63%[Batch 391/391] Loss: 6.101, Accuracy: 18.62%\n[Epoch 4/5] Loss: 6.103, Accuracy: 18.61%, Test Loss: 6.183, Test Accuracy: 11.08%\n[Batch 390/391] Loss: 6.162, Accuracy: 16.75%[Batch 391/391] Loss: 6.162, Accuracy: 16.73%\n[Epoch 5/5] Loss: 6.162, Accuracy: 16.73%, Test Loss: 6.198, Test Accuracy: 10.03%\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.engine.sequential.Sequential at 0x1af7f24c048>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, train_data, x_test, y_test, loss_op, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7e7481938319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=n_epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}